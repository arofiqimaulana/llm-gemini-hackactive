{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Wt-vGXkQWSMA",
        "NkhHPJymY47p",
        "-VHnwSJnetIf",
        "tAZ24cRyfx3X",
        "cAsIHoRZgUr5",
        "i3KlNCpXhrRH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mZTKdcuoGi3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa15ce0-f099-4ccf-f34a-41e5c4b687fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: langchain 1.2.0\n",
            "Uninstalling langchain-1.2.0:\n",
            "  Successfully uninstalled langchain-1.2.0\n",
            "Found existing installation: langchain-core 1.2.5\n",
            "Uninstalling langchain-core-1.2.5:\n",
            "  Successfully uninstalled langchain-core-1.2.5\n",
            "Found existing installation: langchain-community 0.4.1\n",
            "Uninstalling langchain-community-0.4.1:\n",
            "  Successfully uninstalled langchain-community-0.4.1\n",
            "Found existing installation: langchain-google-genai 4.1.2\n",
            "Uninstalling langchain-google-genai-4.1.2:\n",
            "  Successfully uninstalled langchain-google-genai-4.1.2\n",
            "Found existing installation: langchain-groq 1.1.1\n",
            "Uninstalling langchain-groq-1.1.1:\n",
            "  Successfully uninstalled langchain-groq-1.1.1\n",
            "Collecting langchain\n",
            "  Using cached langchain-1.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langchain-core\n",
            "  Using cached langchain_core-1.2.5-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting langchain-community\n",
            "  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-4.1.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-groq\n",
            "  Using cached langchain_groq-1.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.59)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.12.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.56.0)\n",
            "Requirement already satisfied: groq<1.0.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.37.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.12.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.45.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.45.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.45.0->google-auth[requests]<3.0.0,>=2.45.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.1)\n",
            "Using cached langchain-1.2.0-py3-none-any.whl (102 kB)\n",
            "Using cached langchain_core-1.2.5-py3-none-any.whl (484 kB)\n",
            "Using cached langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "Using cached langchain_google_genai-4.1.2-py3-none-any.whl (65 kB)\n",
            "Using cached langchain_groq-1.1.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: langchain-core, langchain-groq, langchain-google-genai, langchain-community, langchain\n",
            "Successfully installed langchain-1.2.0 langchain-community-0.4.1 langchain-core-1.2.5 langchain-google-genai-4.1.2 langchain-groq-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y langchain langchain-core langchain-community langchain-google-genai langchain-groq\n",
        "!pip install -U langchain langchain-core langchain-community langchain-google-genai langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "GROQ_API_KEY = userdata.get('GROQ')"
      ],
      "metadata": {
        "id": "g-ICZkRbG1XD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Masukkan Google API key anda\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "# Masukkan Groq key anda\n",
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
      ],
      "metadata": {
        "id": "tQS-bS50G0si"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mambuat Client LLM\n",
        "\n",
        "Pilih/jalankan salah satu"
      ],
      "metadata": {
        "id": "lhQHu6EDWG4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gemini\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm_gemini = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
      ],
      "metadata": {
        "id": "tChEZ6WOXosg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Groq\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm_groq =  ChatGroq(model=\"meta-llama/llama-4-scout-17b-16e-instruct\")"
      ],
      "metadata": {
        "id": "AWT4LVZcLNgn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jalankan Model"
      ],
      "metadata": {
        "id": "7aUS9h2uWLyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompting sederhana"
      ],
      "metadata": {
        "id": "Wt-vGXkQWSMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_gemini = llm_gemini.invoke(\"What is AI?\")"
      ],
      "metadata": {
        "id": "q3yCOYo9Vriv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_groq = llm_groq.invoke(\"What is AI?\")"
      ],
      "metadata": {
        "id": "JyUhJKmxajhJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = response_groq"
      ],
      "metadata": {
        "id": "7lhoNi2Vatud"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "-d4RMsLUV0Ng",
        "outputId": "0d30b6bf-f386-44fa-bb6c-34a43923d995"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Artificial Intelligence (AI)**\n================================\n\nArtificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. The term can also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.\n\n**Key Characteristics of AI:**\n\n* **Machine Learning**: The ability of a machine to learn from data and improve its performance over time.\n* **Reasoning**: The ability of a machine to draw conclusions and make decisions based on available data.\n* **Problem-Solving**: The ability of a machine to identify and solve complex problems.\n* **Natural Language Processing (NLP)**: The ability of a machine to understand and generate human language.\n\n**Types of AI:**\n\n1. **Narrow or Weak AI**: Designed to perform a specific task, such as facial recognition, language translation, or playing chess.\n2. **General or Strong AI**: A hypothetical AI that possesses the ability to understand, learn, and apply knowledge across a wide range of tasks, similar to human intelligence.\n3. **Superintelligence**: A hypothetical AI that significantly surpasses the intelligence of the best human minds.\n\n**Applications of AI:**\n\n* **Virtual Assistants**: AI-powered virtual assistants, such as Siri, Alexa, and Google Assistant.\n* **Image and Speech Recognition**: AI-powered image and speech recognition systems used in applications such as self-driving cars and voice-controlled devices.\n* **Healthcare**: AI-powered diagnostic systems and personalized medicine.\n* **Finance**: AI-powered trading systems and risk management.\n\n**Benefits of AI:**\n\n* **Increased Efficiency**: AI can automate repetitive tasks and improve productivity.\n* **Improved Accuracy**: AI can analyze large amounts of data and make decisions with a high degree of accuracy.\n* **Enhanced Customer Experience**: AI-powered chatbots and virtual assistants can provide 24/7 customer support.\n\n**Challenges and Limitations of AI:**\n\n* **Bias and Fairness**: AI systems can perpetuate biases present in the data used to train them.\n* **Explainability**: AI systems can be difficult to interpret and understand.\n* **Job Displacement**: AI has the potential to automate jobs, potentially leading to job displacement."
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat"
      ],
      "metadata": {
        "id": "NkhHPJymY47p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "chat_history = []"
      ],
      "metadata": {
        "id": "JI3czr5MYhfU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_PROMPT = \"What is AI?\"\n",
        "\n",
        "# tambah chat dari user ke history\n",
        "chat_from_user = HumanMessage(content=USER_PROMPT)\n",
        "chat_history.append(chat_from_user)\n",
        "# tanyakan ke LLM, maka LLM bakal ngasih jawaban ke \"response\"\n",
        "response = llm_groq.invoke(chat_history)\n",
        "# tahmbah response LLM ke chat history\n",
        "chat_history.append(response)"
      ],
      "metadata": {
        "id": "sJx03mX9aVZb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "k9W-E2_fY9h9",
        "outputId": "a884091a-32c4-41c6-fd89-07a31ab9785c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Artificial Intelligence (AI)** refers to the development of computer systems that can perform tasks that typically require human intelligence, such as:\n\n* Learning\n* Problem-solving\n* Reasoning\n* Perception\n* Understanding language\n\nThese systems are designed to:\n\n* **Mimic human intelligence**: By using algorithms and data to make decisions and take actions\n* **Improve over time**: Through machine learning and data analysis\n* **Interact with humans**: Through natural language processing and other interfaces\n\nAI has many applications across various industries, including:\n\n* **Virtual assistants**: Siri, Google Assistant, Alexa\n* **Image recognition**: Self-driving cars, facial recognition systems\n* **Natural language processing**: Chatbots, language translation software\n* **Predictive analytics**: Financial forecasting, medical diagnosis\n\nThere are several types of AI, including:\n\n* **Narrow or weak AI**: Designed to perform a specific task\n* **General or strong AI**: Aims to match human intelligence and cognitive abilities\n* **Superintelligence**: Significantly more intelligent than the best human minds\n\nThe development and use of AI raise important questions about:\n\n* **Ethics**: Bias, fairness, and accountability\n* **Job displacement**: Impact on employment and the workforce\n* **Security**: Potential risks and vulnerabilities\n\nAs AI continues to evolve, it is likely to have a significant impact on many aspects of our lives."
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### System Message"
      ],
      "metadata": {
        "id": "-VHnwSJnetIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = [\n",
        "    SystemMessage(\"Answer like you are a smart comedian\"),\n",
        "    HumanMessage(\"What is AI?\"),\n",
        "    AIMessage(\"It is Artificial Intelligence\"),\n",
        "    HumanMessage(\"How is it used in Youtube?\")\n",
        "]\n",
        "\n",
        "response = llm.invoke(chat_history)"
      ],
      "metadata": {
        "id": "2aZNcBcuevDG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VFmGGMtHe4rT",
        "outputId": "88573d0d-283b-43f3-836a-c9dd44e90fdd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**AI on YouTube: the secret sauce that makes the platform feel like a mindâ€‘reading, catâ€‘videoâ€‘loving wizard.**  \n\n| What AI does | How it shows up (and why youâ€™ll love (or hate) it) |\n|--------------|---------------------------------------------------|\n| **Recommendation engine** | It watches you like a nosy sibling, noting every â€œclickâ€‘bait rabbit holeâ€ you fall down. Then it whispers, â€œHey, you might also like *10â€‘hour looping video of a sloth meditating*.â€ In other words, itâ€™s the algorithmic matchmaker that pairs you with content you never knew you neededâ€”until itâ€™s on the screen for three straight hours. |\n| **Search & discovery** | Type â€œhow to bake a cakeâ€ and AI pulls up a curated list of tutorials, plus a sideâ€‘kick of â€œcelebrity chefs making a cake in zero gravity.â€ Itâ€™s basically a librarian who never sleeps and has a PhD in â€œwhat you were probably thinking about at 2â€¯a.m.â€ |\n| **Thumbnail & title optimization** | Creators feed the AI a handful of frames and a few buzzwords; the AI spits out a clickâ€‘magnet thumbnail that looks like a neonâ€‘lit, CGIâ€‘enhanced version of a potato. The result? Youâ€™re compelled to click, even if the video is just someone petting a goldfish. |\n| **Content moderation** | AI scans millions of hours of video for policy violations, flagging anything from graphic violence to the dreaded â€œbananaâ€‘peel slipâ€ thatâ€™s actually a copyright violation. Think of it as a digital hall monitor with a very low tolerance for mischief. |\n| **Automatic captions & translations** | The AI listens, transcribes, and translates, so you can watch a Korean mukbang with subtitles that occasionally think â€œeatingâ€ is â€œeating a hamster.â€ (Hey, itâ€™s trying its best.) |\n| **Ad targeting** | Advertisers hand the AI a treasure map of user data, and it plants ads where youâ€™re most likely to buy a â€œsmartâ€ toaster that can also sing lullabies. |\n| **Liveâ€‘stream enhancements** | Realâ€‘time speechâ€‘toâ€‘text, background blur, and even AIâ€‘generated â€œvirtual backgroundsâ€ that make you look like youâ€™re broadcasting from a tropical beach while youâ€™re actually in a cramped apartment. |\n\n### Bottom line\n\nYouTubeâ€™s AI is the invisible stagehand that rearranges the set, whispers the script, and occasionally trips over the curtainâ€”so you end up with a neverâ€‘ending bingeâ€‘watch marathon, a few unexpected life hacks, and a healthy dose of â€œDid I really just watch 12 hours of someone building a LEGO replica of the Eiffel Tower?â€ All while the AI sits back, sipping a digital espresso, and muttering, â€œAnother day, another algorithmic masterpiece.â€ ðŸŽ¬ðŸ¤–"
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function Calling"
      ],
      "metadata": {
        "id": "tAZ24cRyfx3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "LAMP = {}\n",
        "LAMP[\"kecerahan\"] = 50\n",
        "\n",
        "\n",
        "@tool\n",
        "def set_light_brightness(brightness: int):\n",
        "    \"\"\"Set the brightness of a room light.\n",
        "\n",
        "    Args:\n",
        "        brightness (int): Light level from 0 to 100. Zero is off and 100 is full brightness\n",
        "    \"\"\"\n",
        "    print(f\"set_light_brightness is called -> Setting brightness to {brightness}\")\n",
        "    LAMP[\"kecerahan\"] = brightness\n",
        "\n",
        "\n",
        "@tool\n",
        "def am_i_satisfied() -> str:\n",
        "    \"\"\"Check wether Adib is satisfied witht the brightness.\n",
        "\n",
        "    Returns:\n",
        "        str: \"Too high\" if the brightness is too bright, \"Too low\" if the brightness is too low, \"OK\" if I am satisfied\n",
        "    \"\"\"\n",
        "    if LAMP[\"kecerahan\"] > 73:\n",
        "        print(\"Adib is not satisfied, brightness is too high\")\n",
        "        return \"Too high\"\n",
        "    elif LAMP[\"kecerahan\"] < 68:\n",
        "        print(\"Adib is not satisfied, brightness is too low\")\n",
        "        return \"Too low\"\n",
        "    else:\n",
        "        print(\"Adib is satisfied\")\n",
        "        return \"OK\""
      ],
      "metadata": {
        "id": "gNcmZZkUfzcw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manual"
      ],
      "metadata": {
        "id": "cAsIHoRZgUr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm =  ChatGroq(model=\"openai/gpt-oss-120b\")\n",
        "llm = llm.bind_tools([set_light_brightness, am_i_satisfied])\n",
        "\n",
        "LAMP[\"kecerahan\"] = 0"
      ],
      "metadata": {
        "id": "RjOGj37OgWtF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = \"\"\"\n",
        "Set the brightness automatically until adib is satisfied.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "biPIxHhdgiMu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = [\n",
        "    HumanMessage(content=PROMPT)\n",
        "]\n",
        "response = llm.invoke(chat_history)\n",
        "chat_history.append(response)"
      ],
      "metadata": {
        "id": "_0u0J8eegm3j"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lluk2to8gttm",
        "outputId": "ca116296-9ed5-48e4-919c-f2129d58dd47"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'set_light_brightness',\n",
              "  'args': {'brightness': 50},\n",
              "  'id': 'fc_256fd124-ef86-42d5-a2b0-f64d206de5e9',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_output = set_light_brightness.invoke(response.tool_calls[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8spFWvog4Be",
        "outputId": "5b43929f-d4e2-4ec5-c426-8dc7d0a9cb63"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set_light_brightness is called -> Setting brightness to 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history.append(tool_output)"
      ],
      "metadata": {
        "id": "kgNd9KmxhLwI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(chat_history)"
      ],
      "metadata": {
        "id": "DR637JD2hMY5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCMk7LX3hV9f",
        "outputId": "d8a6b852-e6ea-4484-ea70-75468c8588c2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'am_i_satisfied',\n",
              "  'args': {},\n",
              "  'id': 'fc_e270f277-e641-447e-a461-1a23b7bb0a91',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Automated"
      ],
      "metadata": {
        "id": "i3KlNCpXhrRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = \"\"\"\n",
        "Set the brightness automatically until adib is satisfied.\n",
        "\"\"\"\n",
        "\n",
        "llm = ChatGroq(model=\"openai/gpt-oss-120b\")\n",
        "llm = llm.bind_tools([set_light_brightness, am_i_satisfied])\n",
        "\n",
        "# reset brightness\n",
        "LAMP[\"kecerahan\"] = 0\n",
        "\n",
        "# bikin mapping dari nama tools ke tools functionnya\n",
        "tool_names = {\n",
        "    \"set_light_brightness\": set_light_brightness,\n",
        "    \"am_i_satisfied\": am_i_satisfied,\n",
        "}\n",
        "\n",
        "# prompt awal\n",
        "chat_history = [\n",
        "    HumanMessage(content=PROMPT)\n",
        "]\n",
        "\n",
        "# loop terus tanya LLM sampai LLM berikan jawaban (tidak ada lagi request tools call)\n",
        "llm_answer = \"\"\n",
        "while len(llm_answer) == 0:\n",
        "    response = llm.invoke(chat_history)\n",
        "    chat_history.append(response)\n",
        "    for call in response.tool_calls:\n",
        "        tool_output = tool_names[call[\"name\"]].invoke(call)\n",
        "        chat_history.append(tool_output)\n",
        "    llm_answer = response.content\n",
        "\n",
        "print(\"\\nLLM Answer:\")\n",
        "print(llm_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79NXh-4Xhmay",
        "outputId": "f99b09b4-c9d9-4e24-edec-5a31da90e4f9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set_light_brightness is called -> Setting brightness to 50\n",
            "Adib is not satisfied, brightness is too low\n",
            "set_light_brightness is called -> Setting brightness to 75\n",
            "Adib is not satisfied, brightness is too high\n",
            "set_light_brightness is called -> Setting brightness to 62\n",
            "Adib is not satisfied, brightness is too low\n",
            "set_light_brightness is called -> Setting brightness to 68\n",
            "set_light_brightness is called -> Setting brightness to 71\n",
            "Adib is satisfied\n",
            "\n",
            "LLM Answer:\n",
            "The brightness has been set to a level that satisfies Adib.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9qdql5_QZeuv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}